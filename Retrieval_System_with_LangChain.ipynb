{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPqoKnkfkC25tjrCSq18kXs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/codeREXus/langchain-learnings/blob/main/Retrieval_System_with_LangChain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RetreivalQA System with Langchain\n",
        "\n",
        "##### This project involves building up a RetrivalQA System leveraging Langchain and Google Gemini Embedding Model\n",
        "\n",
        "##Steps:\n",
        "\n",
        "#### > import the necessary libraries\n",
        "#### > Set up the model by providing your API keys as Secret\n",
        "#### > Take the url of the website as input and load the webpage.\n",
        "#### > The Last two cells are for testing, One has tests for Taj Mahal the second could be used for custom results."
      ],
      "metadata": {
        "id": "YMtYK0lKZBR1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Requirements (install and restart the kernel/session)"
      ],
      "metadata": {
        "id": "ZGl8SkQ6QpQv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain langchain_experimental langchain_community langchain_google_genai\n",
        "!pip install -q langchainhub\n",
        "!pip install -q pypdf chromadb\n",
        "!pip install -q numpy==1.26.4\n",
        "!pip install -q lxml_html_clean\n",
        "!pip install newspaper3k"
      ],
      "metadata": {
        "id": "p9df3arY8laA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the Libraries"
      ],
      "metadata": {
        "id": "XjCyLcQJQxtQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.documents import Document\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "from langchain.chains import RetrievalQA\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCVPelVAU2SH",
        "outputId": "ca112031-1b13-42a1-8026-a389e1d9f9d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_community.utils.user_agent:USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set-Up the Embedding Model"
      ],
      "metadata": {
        "id": "D6ThelPsQ1W5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embed_model = GoogleGenerativeAIEmbeddings(\n",
        "    model=\"models/embedding-001\",\n",
        "    google_api_key=userdata.get('google_api')\n",
        ")"
      ],
      "metadata": {
        "id": "4jpCTG3XY5rt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scrape the data from the website"
      ],
      "metadata": {
        "id": "boMsKRlTRD33"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import newspaper\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "# The URL you want to scrape\n",
        "url = input(\"Enter the URL: \")\n",
        "\n",
        "try:\n",
        "    # Create an Article object\n",
        "    article = newspaper.Article(url)\n",
        "\n",
        "    # Download and parse the article\n",
        "    article.download()\n",
        "    article.parse()\n",
        "\n",
        "    # Get the clean text\n",
        "    page_content = article.text\n",
        "\n",
        "    if not page_content:\n",
        "        print(\"Failed to extract content. The page might be rendered with JavaScript or have an unusual structure.\")\n",
        "        documents = []\n",
        "    else:\n",
        "        # Create a LangChain Document\n",
        "        # This allows you to plug it directly into the rest of your code\n",
        "        metadata = {\"source\": url, \"title\": article.title}\n",
        "        doc = Document(page_content=page_content, metadata=metadata)\n",
        "        documents = [doc]\n",
        "        print(f\"Successfully extracted content from: {article.title}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")\n",
        "    documents = []\n",
        "\n",
        "\n",
        "# The rest of your code continues from here...\n",
        "if documents:\n",
        "    text_splitter = ...\n",
        "    chunks = ...\n",
        "    # etc."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owuoJJncNTim",
        "outputId": "84454b35-3d2c-4533-d381-ecb87a9a14bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the URL: https://en.wikipedia.org/wiki/Taj_Mahal\n",
            "Successfully extracted content from: Taj Mahal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=500,\n",
        "    chunk_overlap= 50\n",
        ")\n",
        "chunks = text_splitter.split_documents(documents)"
      ],
      "metadata": {
        "id": "tJJnD2v7ahGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector_store = Chroma.from_documents(chunks,embed_model)\n",
        "retreiver =vector_store.as_retriever(search_kwargs={'k':3})\n",
        "#search_kwargs k=3 states to return top 3 most simmilar results/document/answers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3juT4tRZbBcq",
        "outputId": "1f4e7789-823e-438b-dad7-bf1afb0aec8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "By default the model returns 3 results, change top_k to change the number of outputs"
      ],
      "metadata": {
        "id": "CTtzVYYOR_UK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def search_docs(query, top_k=3):\n",
        "    docs= retreiver.invoke(query)\n",
        "    return docs[:top_k]"
      ],
      "metadata": {
        "id": "hO8ue1FXIDsB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_queries = [\n",
        "    \"Taj Mahal\",\n",
        "    \"who built it?\",\n",
        "    \"Which river flows by?\"\n",
        "]\n",
        "\n",
        "for query in test_queries:\n",
        "    print(f\"\\nQuery: {query}\")\n",
        "    results = search_docs(query)\n",
        "\n",
        "    # Print the results\n",
        "    print(f\"Found {len(results)} relevant documents:\")\n",
        "    for i, doc in enumerate(results):\n",
        "        print(f\"\\nResult {i+1}: {doc.page_content[:1500]}...\")\n",
        "        print(f\"Source: {doc.metadata.get('source', 'Unknown')}\")"
      ],
      "metadata": {
        "id": "K1WaQCu5Oi9A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "queries = []\n",
        "top_k = int(input(\"How many documents you want for a topic: \"))\n",
        "\n",
        "while True:\n",
        "    inp = input(\"Search the doc (or type 'exit' to finish): \")\n",
        "    if inp.lower() == 'exit':\n",
        "        break\n",
        "    queries.append(inp) # Add the user's query to the list\n",
        "\n",
        "print(\"\\\\n--- Search Results ---\")\n",
        "for query in queries:\n",
        "    print(f\"\\n Query: {query}\")\n",
        "    result = search_docs(query, top_k)\n",
        "\n",
        "    print(f\"Found {len(result)} relevant documents:\")\n",
        "    for i, doc in enumerate(result):\n",
        "        print(f\"\\nResult {i+1}: {doc.page_content[:1500]}...\")\n",
        "        print(f\"Source: {doc.metadata.get('source', 'Unknown')}\")"
      ],
      "metadata": {
        "id": "Af9keKCkIaaM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}