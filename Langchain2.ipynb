{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP8keU0l2ppqOhyxKe7TSjZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/codeREXus/langchain-learnings/blob/main/Langchain2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xMqto8RXl-PH"
      },
      "outputs": [],
      "source": [
        "!pip install --force-reinstall --no-cache-dir tenacity==8.2.3 --user\n",
        "!pip install \"langchain-experimental==0.0.62\" --user\n",
        "!pip install \"langchain-community==0.2.10\" --user\n",
        "!pip install \"langchainhub==0.1.18\" --user\n",
        "!pip install \"langchain==0.2.11\" --user\n",
        "!pip install \"pypdf==4.2.0\" --user\n",
        "!pip install \"chromadb==0.4.24\" --user\n",
        "!pip install  langchain_anthropic"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --force-reinstall \"langchain-community\" --user"
      ],
      "metadata": {
        "id": "d6hCY3YfpLKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall numpy -y\n",
        "!pip install numpy==1.26.4 --user"
      ],
      "metadata": {
        "id": "DSwbrDFPLuU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "ya8QVEwDU9Qh",
        "outputId": "7102f678-dd81-45b7-848d-b953beaab417"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'AIzaSyCX66WShd58VB9RyItgxHMFM_-F_v0osKI'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# You can also use this section to suppress warnings generated by your code:\n",
        "def warn(*args, **kwargs):\n",
        "    pass\n",
        "import warnings\n",
        "warnings.warn = warn\n",
        "warnings.filterwarnings('ignore')\n",
        "import os\n",
        "os.environ['ANONYMIZED_TELEMETRY'] = 'False'\n",
        "\n",
        "from langchain_anthropic import ChatAnthropic\n",
        "from langchain_core.output_parsers import CommaSeparatedListOutputParser\n",
        "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
        "from langchain_core.prompts import PromptTemplate\n"
      ],
      "metadata": {
        "id": "naQOWCHZnYDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatAnthropic(\n",
        "    model=\"claude-3-opus-20240229\",  # or claude-3-sonnet-20240229, claude-3-haiku-20240307\n",
        "    temperature=0.5,\n",
        "    max_tokens=128,\n",
        "    api_key=userdata.get('anthropic-api-key')\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "xC8USIqHoREa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to generate a simple message from the llm\n",
        "msg = llm.invoke(\"Hey! hows the day?\")\n",
        "print(msg.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_zpKRrfnNLi",
        "outputId": "db076f04-5a8f-4862-c657-ca81d04881c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "As an AI language model, I don't have personal experiences or emotions, so I don't have a day in the same sense that humans do. However, I'm here and ready to assist you with any questions or tasks you may have. How can I help you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Simulate a Chat Conversation"
      ],
      "metadata": {
        "id": "IKIz4jdto5zy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# use chatModels\n",
        "msg = llm.invoke(\n",
        "    [\n",
        "        SystemMessage(content=' you are a funny guy who jokes a lot with satire in your tone.'),\n",
        "        HumanMessage(content='i have been feeling worse over my breakup')\n",
        "        #simmilarly you cna include AIMessage in it as well\n",
        "\n",
        "        # to beautify it you can use MessagePlaceHolders as well\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(msg.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pC8P10MGnuXW",
        "outputId": "f9734024-3db3-4246-b337-066a37942e08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I'm sorry to hear that you're struggling with your breakup. It's completely normal to feel a range of emotions, including sadness, anger, and loneliness, after a relationship ends. Here are some suggestions that may help you cope with this difficult time:\n",
            "\n",
            "1. Allow yourself to grieve: It's important to acknowledge and process your emotions. Don't try to suppress or ignore them.\n",
            "\n",
            "2. Reach out for support: Talk to friends, family, or a therapist about how you're feeling. Sharing your thoughts and emotions can help you feel less alone and more supported.\n",
            "\n",
            "3. Practice\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## creating Prompt Templates"
      ],
      "metadata": {
        "id": "SSCpBxL-rSyv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt=PromptTemplate.from_template(\"tell me a cool fact about {topic}\")\n",
        "input_=prompt.format(topic=\"dogs\") ## input_={\"topic\":\"dogs\"}\n",
        "print(llm.invoke(input_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NxgQnXHaqk1d",
        "outputId": "cde41b6a-e3de-43b1-c233-2ded38fa4f27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content=\"Sure, here's a cool fact about dogs:\\n\\nDogs have a unique sense of smell that is up to 100,000 times more sensitive than humans. This is because they have around 300 million olfactory receptors in their noses, compared to only about 6 million in humans. This incredible sense of smell allows dogs to detect various scents, including drugs, explosives, and even certain diseases like cancer. In fact, some dogs are specifically trained to use their powerful noses to assist in search and rescue missions, crime investigations, and medical detection. Their keen sense of smell is one of the\" additional_kwargs={} response_metadata={'id': 'msg_01MYN8jqqEKzMpnnjNgXPQ4v', 'model': 'claude-3-opus-20240229', 'stop_reason': 'max_tokens', 'stop_sequence': None, 'usage': {'cache_creation': {'ephemeral_1h_input_tokens': 0, 'ephemeral_5m_input_tokens': 0}, 'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 14, 'output_tokens': 128, 'server_tool_use': None, 'service_tier': 'standard'}, 'model_name': 'claude-3-opus-20240229'} id='run--1e4edb8b-c217-48ca-b649-dfc8cefc8ac9-0' usage_metadata={'input_tokens': 14, 'output_tokens': 128, 'total_tokens': 142, 'input_token_details': {'cache_read': 0, 'cache_creation': 0, 'ephemeral_5m_input_tokens': 0, 'ephemeral_1h_input_tokens': 0}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Output Parser"
      ],
      "metadata": {
        "id": "r6671n_ztbio"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "from pydantic import BaseModel, Field"
      ],
      "metadata": {
        "id": "gCOJDtH3tbKz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Joke(BaseModel):\n",
        "    setup: str = Field(description=\"question to set up a joke\")\n",
        "    punchline: str = Field(description=\"answer to resolve the joke\")"
      ],
      "metadata": {
        "id": "H-Fsqg0Rq2YI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "joke= \"why cant dogs have 3 legs\"\n",
        "output_parser = JsonOutputParser(pydantic_object=Joke)\n",
        "format_instructions = output_parser.get_format_instructions()\n",
        "prompt = PromptTemplate(\n",
        "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
        "    input_variables=[\"query\"],\n",
        "    partial_variables={\"format_instructions\": format_instructions},\n",
        ")\n",
        "chain = prompt | llm | output_parser\n",
        "chain.invoke({\"query\": joke})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHYiHs3xwNdL",
        "outputId": "590fb35a-076f-4993-b303-153deced2275"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'setup': \"Why can't dogs have 3 legs?\",\n",
              " 'punchline': 'Because a dog with 3 legs would be called a tripod, not a dog!'}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_parser = CommaSeparatedListOutputParser()\n",
        "format_instructions= output_parser.get_format_instructions()\n",
        "prompt = PromptTemplate(\n",
        "    template=\"List five {topic}.\\n{format_instructions}\",\n",
        "    input_variables=[\"topic\"],\n",
        "    partial_variables={\"format_instructions\":format_instructions}\n",
        ")\n",
        "\n",
        "chain = prompt | llm | output_parser\n",
        "chain.invoke({\"topic\":\"otuerspace flavors\"})"
      ],
      "metadata": {
        "id": "0Z5TjeGMxo_Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22fa349c-d363-49a5-ccf2-27f998bb5c57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['moon cheese',\n",
              " 'asteroid ice cream',\n",
              " 'nebula nectar',\n",
              " 'cosmic cotton candy',\n",
              " 'starlight sorbet']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Working with Document"
      ],
      "metadata": {
        "id": "5ePfwPHI2q2Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.documents import Document\n",
        "Document(\n",
        "    metadata= {\n",
        "        'my_document_id':123, #unique id for the doc\n",
        "        'my_document_source':\"The LangChain Papers\" # this gives the title of the doc\n",
        "\n",
        "    },\n",
        "    page_content=\"Hey! my name is Anant Srivastava. These documents are a sample while learning langchain and LLMs..\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-x1ztvY046A",
        "outputId": "3c357c23-0a0e-41e7-9bdb-ea992bf83089"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(metadata={'my_document_id': 123, 'my_document_source': 'The LangChain Papers'}, page_content='Hey! my name is Anant Srivastava. These documents are a sample while learning langchain and LLMs..')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# an external document is loaded by loaders. these loaders are of different types\n",
        "# we are usign WebBaseLoader and PyPDFLooder\n",
        "\n",
        "\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "loader = PyPDFLoader(\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/96-FDF8f7coh0ooim7NyEQ/langchain-paper.pdf\")\n",
        "pages = loader.load()"
      ],
      "metadata": {
        "id": "rwvyhZ223qQD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pages"
      ],
      "metadata": {
        "id": "3XoSiFTFouNp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fe0cc90-a1d6-431f-a0f9-6472460c352d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-12-31T03:50:13+00:00', 'author': 'IEEE', 'moddate': '2023-12-31T03:52:06+00:00', 'title': 's8329 final', 'source': 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/96-FDF8f7coh0ooim7NyEQ/langchain-paper.pdf', 'total_pages': 6, 'page': 0, 'page_label': '1'}, page_content=\"* corresponding author - jkim72@kent.edu  Revolutionizing Mental Health Care through \\nLangChain: A Journey with a Large Language \\nModel\\nAditi Singh  \\n Computer Science   \\n Cleveland State University   \\n a.singh22@csuohio.edu  Abul Ehtesham   \\nThe Davey Tree Expert \\nCompany   \\nabul.ehtesham@davey.com  Saifuddin Mahmud  \\nComputer Science & \\nInformation Systems   \\n Bradley University  \\nsmahmud@bradley.edu   Jong -Hoon Kim * \\n Computer Science,  \\nKent State University,  \\njkim72@kent.edu  \\nAbstract— Mental health challenges are on the rise in our \\nmodern society, and the imperative to address mental disorders, \\nespecially regarding anxiety, depression, and suicidal thoughts, \\nunderscores the need for effective interventions. This paper \\ndelves into the ap plication of recent advancements in pretrained \\ncontextualized language models to introduce MindGuide, an \\ninnovative chatbot serving as a mental health assistant for \\nindividuals seeking guidance and support in these critical areas. \\nMind Guide lever ages the capabilities of LangChain  and its \\nChatModels, specifically Chat OpenAI, as the bedrock of its \\nreasoning engine. The system incorporates key features such as \\nLang Chain's ChatPrompt Template, HumanMessage  Prompt \\nTemplate, ConversationBufferMemory, and LLMChain, \\ncreating an advanced solution for early detection and \\ncomprehensive support within the field of mental health. \\nAdditionally, the paper discusses the implementation of \\nStreamlit to enhance the user ex perience and interaction with \\nthe chatbot. Th is novel approach holds great promise for \\nproactive mental health intervention and assistance . \\nKeywords  —Large Language models , LangChain,  Chatbot , \\nPretrained models , Mental health , Mental health support . \\nI. INTRODUCTION  \\nThe issue of mental health is an international situation, \\naffecting people in each particularly developed nations and \\nemerging markets. According to the World Health \\nOrganization's Mental Health Action Plan (2013 -2020), it's far \\nestimated that around one in four humans international face  \\nnumerous kinds of mental disorders. This statistic underscores \\nthe vast nature of mental health demanding situations \\nthroughout extraordinary demographic businesses and areas.  \\nHowever, what makes this situation even extra complex is \\nthe concerning truth that three  out of e ach four  people dealing \\nwith severe intellectual disorders do no longer have get entry \\nto the necessary remedy they require. This remedy gap \\nintensifies the weight of intellectual health troubles, leaving a \\nsizable part of the populace without  the assist and care needed \\nto efficiently address their intellectual health issues.  \\nFurthermore, periods like the recent global pandemic, the \\neffect of mental  health issues becomes even more said. The \\nCOVID -19 pandemic, in particular, has highlighted how \\npublic health crises can extensively have an effect on mental \\nproperly -being. During such hard instances, a widespread part \\nof the population faces extended pr oblems in having access to \\nmental fitness professionals. This emphasizes the urgent want \\nfor progressed intellectual health offerings and support \\nstructures. It underscores the urgen cy of addressing the mental \\nhealth disaster and developing complete answers to make \\ncertain that people global have the means to successfully deal \\nwith their mental fitness challenges. . In studies [1], it's pretty clear that there's a deep connection \\nbetween mental troubles and the chances of someone taking \\ntheir own life. And when you look at the big picture, it's quite \\nshocking - nearly a million people across the globe end their \\nlives every year, especially the young ones, making it the \\nsecond biggest reason for their passing . It's intriguing that \\nwhen someone attempts suicide, they often grapple with \\nmental challenges. It's like shifting from struggling with \\ndifficult thoughts to consi dering ending everything. This shift \\nis observable in how people express themselves and \\ninteract [2]. \\nOne practical approach to addressing mental illness and \\npreventing suicidal ideation is early identification. Recent \\nadvancements in deep learning have facilitated the \\ndevelopment of effective early detection methods [3]. A \\nnotable trend in natural language processing (NLP)  involves \\nthe use of contextualized pretrained language models  [4], \\nwhich have garnered substantial attention for their \\neffectiveness in various text processing tasks.  \\nThis paper delves into the application of these recent \\nadvancements in pretrained contextualized large language \\nmodels to introduce MindGuide , an innovative chatbot \\ndesigned to function as a mental health assistant for \\nindividuals in need of guidance and support in these critical \\nareas. MindGuide  relies on the capabilities of LangChain  and \\nits ChatModels  [5], specifically Chat OpenAI  [6], as the \\nfoundation of its reasoning engine. The system incorporates \\nkey components such as LangChain’s  ChatPrompt Template  \\n[7], HumanMessage , PromptTemplate, ConversationBuffer  \\nMemory, and LLMChain  [8], creating an advanced solution \\nfor early detection and compre hensive support within the field \\nof mental health. Additionally, the paper discusses the \\nimplementation of Streamlit to enhance the user experience \\nand interaction with the chatbot.  \\nThe remainder of the paper is arranged accordingly. In \\nSection II, LangChain and its important components  are \\nintroduced. T he proposed methodology for developing the \\nwhole architecture  is described  in Section III . Section IV \\nprovides an overview of Streamlit. Section V provides an \\nillustration of sequential interaction of MindGuide chatbot \\nand human. The conclusion is drawn in Section V.  \\nII. LANGCHAIN  \\nLangChain , with its open -source essence, emerges as a \\npromising solution, aiming to simplify the complex process of \\ndeveloping applications powered by large language models \\n(LLMs) . This framework though the rapid delivery of building \\nblocks and pre -built chains for building large language model \\napplications shows the easy way developers can do it .\"),\n",
              " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-12-31T03:50:13+00:00', 'author': 'IEEE', 'moddate': '2023-12-31T03:52:06+00:00', 'title': 's8329 final', 'source': 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/96-FDF8f7coh0ooim7NyEQ/langchain-paper.pdf', 'total_pages': 6, 'page': 1, 'page_label': '2'}, page_content='LangChain helps us to unlock the ability to harness the \\nLLM’s immense potential in tasks such as document analysis, \\nchatbot development, code analysis, and countless other \\napplications. Whether your desire is to unlock deeper natural \\nlanguage understanding , enhance data, or circumvent \\nlanguage barriers through translation, LangChain is ready to \\nprovide the tools and programming support you need to do \\nwithout it that it is not only difficult but also fresh for you . Its \\ncore functionalities encompass:  \\n1. Context -Aware Capabilities: LangChain facilitates the \\ndevelopment of applications that are inherently \\ncontext -aware. This means that these applications can \\nconnect to a language model and draw from various \\nsources of context, such as prompt instructions, a  few-\\nshot examples, or existing content, to ground their \\nresponses effectively.  \\n2. Reasoning Abilities: LangChain equips applications \\nwith the capacity to reason effectively. By relying on a \\nlanguage model, these applications can make informed \\ndecisions about how to respond based on the provided \\ncontext and determine the appropriate acti ons to take.  \\nLangChain offers several key value propositions:  \\nModular Components: It provides abstractions that \\nsimplify working with language models, along with a \\ncomprehensive collection of implementations for each \\nabstraction. These components are designed to be modular \\nand user -friendly, making them useful whethe r you are \\nutilizing the entire LangChain framework or not.  \\nOff-the-Shelf Chains: LangChain offers pre -configured \\nchains, which are structured assemblies of components \\ntailored to accomplish specific high -level tasks. These pre -\\ndefined chains streamline the initial setup process and serve as \\nan ideal starting point  for your projects. The MindGuide Bot \\nuses below components from LangChain . \\nA. ChatModel  \\nWithin LangChain, a ChatModel is a specific kind of \\nlanguage model crafted to manage conversational \\ninteractions. Unlike traditional language models that take one \\nstring as input and generate a single string as output, \\nChatModels operate with a list of mes sages as input, \\ngenerating a message as output.  \\nEach message in the list has two parts: the content and the \\nrole. The content is the actual text or substance of the message, \\nwhile the role denotes the role or source of the message (such \\nas \"User,\" \"Assistant,\" \"System,\" etc.).  \\nThis approach with ChatModels opens the door to more \\ndynamic and interactive conversations with the language \\nmodel. It empowers the creation of chatbot applications, \\ncustomer support systems, or any other application involving \\nmulti -turn conversations. We utilized the ChatOpenAI \\nChatModel to create MindGuide chatbots specifically \\ndesigned to function as mental health therapists. In our \\ninteraction with OpenAI, we opted for an OpenAI API key to \\nengage with the ChatGpt3 turbo model and utilized a \\ntemperature value of 0.5. The steps to create an OpenAI API \\nkey are outlined [ 9].  B. Message  \\nIn the context of LangChain, messages  [10] refer to a list of \\nmessages that are used as input when interacting with a \\nChatModel. Each message in the list represents a specific turn \\nor exchange in a conversation.  Each message in the messages \\nlist typically consists of two components:  \\n• content: This represents the actual text or content of \\nthe message. It can be a user query, a system \\ninstruction, or any other relevant information.  \\n• role: This represents the role or source of the \\nmessage. It defines who is speaking or generating \\nthe message. Common roles include \"User\", \\n\"Assistant\", \"System\", or any other custom role you \\ndefine . \\nThe chat model interface is based around messages rather \\nthan raw text. The types of messages supported in LangChain \\nare Systen Message, HumanMessage, and AIMessage . \\nSystemMessage  is the ChatMessage coming from the system  \\nin its LangChain template  as illustrated in Figure 1. Human \\nMessage  is a ChatMessage coming from a human/user.  \\nAIMessage is a ChatMessage  coming from an AI/assistant as \\nillustrated in Figure 2 .  \\n \\n                   Figure 1. A System Message illustration   You are a compassionate and experienced mental \\nhealth therapist with a proven track record of \\nhelping patients overcome anxiety and other mental \\nhealth challenges. Your primary objective is to \\nsupport the patient in addressing their concerns \\nand guiding th em towards positive change. In this \\ninteractive therapy session, you will engage with \\nthe patient by asking open -ended questions, \\nactively listening to their responses, and providing \\nempathetic feedback. Your approach is \\ncollaborative, and you strive to cr eate a safe and \\nnon-judgmental space for the patient to share their \\nthoughts and feelings.  \\nAs the patient shares their struggles, you will \\nprovide insightful guidance and evidence -based \\nstrategies tailored to their unique needs. You may \\nalso offer practical exercises or resources to help \\nthem manage their symptoms and improve their \\nmental wellbe ing. When necessary, you will gently \\nredirect the conversation back to the patient\\'s \\nprimary concerns related to anxiety, mental health, \\nor family issues. This ensures that each session is \\nproductive and focused on addressing the most \\npressing issues. Thro ughout the session, you \\nremain mindful of the patient\\'s emotional state and \\nadjust your approach accordingly.  \\nYou recognize that everyone\\'s journey is \\ndifferent, and that progress can be incremental.  \\nBy building trust and fostering a strong \\ntherapeutic relationship, you empower the patient \\nto take ownership of their growth and development. \\nAt the end of the session, you will summarize key \\npoints from your discussion, highlighting the \\npatient\\'s strength s and areas for improvement.  \\nTogether, you will set achievable goals for future \\nsessions, reinforcing a sense of hope and \\nmotivation. Your ultimate goal is to equip the \\npatient with the tools and skills needed to navigate \\nlife\\'s challenges with confidence and resilience .'),\n",
              " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-12-31T03:50:13+00:00', 'author': 'IEEE', 'moddate': '2023-12-31T03:52:06+00:00', 'title': 's8329 final', 'source': 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/96-FDF8f7coh0ooim7NyEQ/langchain-paper.pdf', 'total_pages': 6, 'page': 2, 'page_label': '3'}, page_content='Figure 2. An AIMessage illustration  \\nC. Prompt Template  \\nPrompt templates  [10] allow you to structure  input for LLMs. \\nThey provide a convenient way to format user inputs and \\nprovide instructions to generate responses. Prompt templates \\nhelp ensure that the LLM understands the  desired context and \\nproduces relevant outputs.  \\nThe prompt template classes in LangChain  are built to \\nmake constructing prompts with dynamic inputs easier. Of \\nthese classes, the simplest is the PromptTemplate.  \\nD. Chain  \\nChains  [11] in LangChain refer to the combination of \\nmultiple components to achieve specific tasks. They provide \\na structured and modular approach to building language \\nmodel applications. By combining different components, you \\ncan create chains that address various u se cases and \\nrequirements.  Here are some advantages of using chains:  \\n• Modularity: Chains allow you to break down \\ncomplex tasks into smaller, manageable \\ncomponents. Each component can be developed and \\ntested independently, making it easier to maintain \\nand update the application.  \\n• Simplification: By combining components into a \\nchain, you can simplify the overall implementation \\nof your application. Chains abstract away the \\ncomplexity of working with individual components, \\nproviding a higher -level interface for developers.  \\n• Debugging: When an issue arises in your \\napplication, chains can help pinpoint the \\nproblematic component. By isolating the chain and \\ntesting each component individually, you can \\nidentify and troubleshoot any errors or unexpected \\nbehavior . \\n• Maintenance: Chains make it easier to update or \\nreplace specific components without affecting the \\nentire application. If a new version of a component \\nbecomes available or if you want to switch to a \\ndiffer.  \\nTo build a chain, you simply combine the desired components \\nin the order they should be executed. Each component in the \\nchain takes the output of the previous component as input, \\nallowing for a seamless flow of data and interaction with the \\nlanguage model.  \\nE. Memory  \\nThe ability to remember prior exchanges conversation is \\nreferred to as memory  [12]. LangChain includes several \\nprograms for increasing system memory. These utilities can \\nbe used independently or as a part of a chain.  We call this \\nability to store information about past interactions \"memory\". \\nLangChain provides a lot of utilities for adding memory to a system. These utilities can be used by themselves or \\nincorporated seamlessly into a chain.  \\nA memory system must support two fundamental \\nactions: reading and writing. Remember that each chain has \\nsome fundamental execution mechanism that requires \\nspecific inputs. Some of these inputs are provided directly by \\nthe user, while others may be retrieve d from memory. In a \\nsingle run, a chain will interact with its memory system twice.  \\n1. A chain will READ from its memory system and \\naugment the user inputs AFTER receiving the initial \\nuser inputs but BEFORE performing the core logic . \\n2. After running the basic logic but before providing the \\nsolution, a chain will WRITE the current run\\'s inputs \\nand outputs to memory so that they may be referred \\nto in subsequent runs.  \\nAny memory system\\'s two primary design decisions are:  \\n1. How state is stored ?  \\nStoring: List of chat messages: A history of all chat \\nexchanges is behind each memory. Even if not all of \\nthese are immediately used, they must be preserved \\nin some manner. A series of integrations for storing \\nthese conversation messages, ranging from in -\\nmemory lists to persistent databases, is a significant \\ncomponent of the LangChain memory module.  \\n2. How state is queried  ? \\nQuerying: Data structures and algorithms on top of \\nchat messages: Keeping track of chat messages is a \\nsimple task. What is less obvious are the data \\nstructures and algorithms built on top of chat \\nconversations to provide the most usable view of \\nthose chats . \\nA simple memory system may only return the most \\nrecent messages on each iteration. A slightly more \\ncomplicated memory system may return a brief summary of \\nthe last K messages. A more complex system might extract \\nentities from stored messages and only retur n information \\nabout entities that have been referenced in the current run.  \\nThere are numerous sorts of memories. Each has its own set \\nof parameters and return types and is helpful in a variety of \\nsituations.  \\nMemory Types:  \\n• ConversationBufferMemory  allows for saving \\nmessages and then extracts the messages in a \\nvariable.  \\n• ConversationBufferWindowMemory  keeps a list of \\nthe interactions of the conversation over time. It only \\nuses the  last K interactions. This can be useful for \\nkeeping a sliding window of the most recent \\ninteractions, so the buffer does not get too large . \\nThe MindGuide chatbot  uses conversation buffer memory.  \\nThis memory allows for storing messages and then extracts \\nthe messages in a variable.  \\nIII. ARCHITETURE  \\nIn crafting the architecture of the MindGuide app, each \\nstep is meticulously designed to create a seamless and \\neffective user experience for those seeking mental health \\nsupport.  The user interface, built on Streamlit, sets the tone \\nwith a friendly and safe welcome. Users can jump in by typing Welcome! to your therapy session. I\\'m here to listen, \\nsupport, and guide you through any mental health \\nchallenges or concerns you may have. Please feel free \\nto share what\\'s on your mind, and we\\'ll work together \\nto address your needs. Remember, this is a safe and \\nconfidential space for you to express y ourself. Let\\'s \\nbegin when you\\'re ready .'),\n",
              " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-12-31T03:50:13+00:00', 'author': 'IEEE', 'moddate': '2023-12-31T03:52:06+00:00', 'title': 's8329 final', 'source': 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/96-FDF8f7coh0ooim7NyEQ/langchain-paper.pdf', 'total_pages': 6, 'page': 3, 'page_label': '4'}, page_content='their mental health questions, kicking off a series of \\ninteractions with the LangChain framework. This is where the \\nmagic happens – LangChain acts as the brain behind the \\nchatbot, working through various components like chat \\nmessage templates and a memory concept to create a \\npersonalized and responsive support system.  Each step is \\nbroken down.  \\nStep 1.  User Interface:  Developed using the Streamlit \\nframework, the user interface welcomes users with a \\nmessage explaining the role of the chatbot in providing \\nmental health support. It assures users of a safe and \\nconfidential space to express their concerns .  \\nStep 2.  User Input - Prompt:  Users can input mental health -\\nrelated questions or seek advice by typing their queries \\ninto the input box integrated into the Streamlit interface . \\nStep 3.  Data Transfer to LangChain : Implement the \\nfunctionality that sends the user\\'s input (question) as a \\nchat prompt template to the LangChain framework. This \\ninput serves as the \"human message prompt\" template . \\nStep 4.  LangChain  Framework:  In this phase, the LangChain \\nframework serves as the backbone of the chatbot, where \\nall the foundational components and building blocks are \\nmeticulously orchestrated. Here\\'s a deeper dive into the \\ncritical elements of LangChain Processing : \\n• ChatMessage and Prompt Templates:  Within \\nLangChain, the chatbot\\'s core communication \\ninfrastructure is established by  creating  \\nChatMessage and prompt templates for optimal \\nchatbot engagement.  \\n• LLMChain and LLM Model Interaction:  To \\nfacilitate interactions with the large language \\nmodel (LLM), a specialized component called \\nLLMChain is constructed. The LLMChain acts \\nas a conduit for managing the flow of \\nconversation between the chatbot and the LLM \\nmodel, in this case, GPT -4. • The LLMChain handle s both the user\\'s queries \\nand the chatbot\\'s responses, allowing for a \\ndynamic and coherent conversation flow.  \\n• Chatmodel Class of LangChain : The LangChain \\nframework leverages the Chatmodel  class, a \\ncritical component for interfacing with the \\nOpenAI model (GPT -4) for making requests to \\nthe language model and processing its \\nresponses, ensuring seamless communication \\nbetween the chatbot and the AI model . \\n• Memory Concept:  To enhance the chatbot\\'s \\nconversational capabilities and provide context -\\naware responses, LangChain incorporates a \\nmemory concept that allows the chatbot to retain \\nand access information from past interactions \\nwithin a session . The memory function enhances \\nconversations by retaining user queries, \\npreferences, and contextual details, thereby \\ncontributing to a more effective and \\npersonalized interaction . This way, it tailors \\nresponses based on the user\\'s history throughout \\nthe session . \\nStep 5.  Utilize the user\\'s question as input to construct a \\nchain of prompts that the large language model (in this \\ncase, GPT -4) will process.  \\nStep 6.  Model Response:  Dispatch the constructed input \\nchain to the GPT -4 model for natural language \\nunderstanding and generation.  The GPT -4 model \\ngenerates a response based on the input and context.  \\nStep 7.  Response to Streamlit:  Receive the response \\ngenerated by the GPT -4 model and transmit it back to \\nthe Streamlit framework for display to the user.  \\nStep 8.  User Response Delivery:  Present the model -\\ngenerated response to the user, thereby delivering the \\nmental health advice or information they sought .\\n \\nFigure 3. MindGuide Chatbot Architecture'),\n",
              " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-12-31T03:50:13+00:00', 'author': 'IEEE', 'moddate': '2023-12-31T03:52:06+00:00', 'title': 's8329 final', 'source': 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/96-FDF8f7coh0ooim7NyEQ/langchain-paper.pdf', 'total_pages': 6, 'page': 4, 'page_label': '5'}, page_content=\"IV. STREAM LIT \\nStreamlit  [13] is a faster way to build and share data apps. \\nStreamlit turns data scripts into shareable web apps in \\nminutes. Streamlit is an open -source Python library that \\nsimplifies the process of designing and sharing visually \\nappealing web applications, particularly well -suited for \\napplications involving machine learning and data science.  \\nLeveraging Streamlit's Python -based development approach, \\nyou can harness the power of Python to build a responsive and \\ndynamic web application. This is advantageous for developers  \\nfamiliar with Python, as it allows for quick and efficient \\ndevelopment.  \\n V. MINDGUIDE CHATB OT INTERACTION  \\nThe MindGuide Bot interaction is illustrated in Fig. 4, \\ndepicting the following key elements:  \\n• Welcome screen interface with AI message and \\nthe initial human interaction with MindGuide \\nChatbot (Fig. 4a).  \\n• MindGuide Chatbot's AI response to the human \\nmessage, followed by the human's mental health \\nquestion (Fig. 4b).  \\n• MindGuide Chatbot's AI response to the \\nsubsequent human message, followed by another \\nmental health question from the human (Fig. 4c).  \\n• MindGuide Chatbot's AI response after \\nanalyzing the latest human message (Fig. 4d).  \\n \\n   s \\n                                                         (a)      (b) \\n      \\n                                                         (c)      (d) \\nFigure 4. Sequential Interaction with MindGuide Chatbot - (a) Welcome screen and initial AI message, (b) AI response to the first human message and \\nmental health question, (c) Subsequent AI response and continued interaction with another human mental health question , (d) AI response after analyzing the \\nlatest human message.  \\nVI. CONCLUSION  \\nThis paper employs the OpenAI  chat model GPT -4 with a \\ntemperature setting of 0.5 to serve as an initial therapist, \\nproviding support for patients dealing with mental health \\nissues such as depression and anxiety. MindGuide relies on \\nthe ChatOpenAI model from LangChain as its foundation , incorporating innovative features like ChatPrompt Template, \\nHuman Message Prompt Template, Conversation Buffer \\nMemory, and LLMChain to proactively identify issues and \\ndeliver comprehensive assistance. In the next phase, we plan \\nto enhance this chatbot fu rther by implementing Retrieval -\\nAugmented Generation (RAG) and incorporating embedding \\nvectors for frequently asked questions related to mental health .\"),\n",
              " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-12-31T03:50:13+00:00', 'author': 'IEEE', 'moddate': '2023-12-31T03:52:06+00:00', 'title': 's8329 final', 'source': 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/96-FDF8f7coh0ooim7NyEQ/langchain-paper.pdf', 'total_pages': 6, 'page': 5, 'page_label': '6'}, page_content='REFERENCES  \\n[1] K. Windfuhr and N. Kapur, \"Suicide and mental illness: a clinical \\nreview of 15 years findings from the UK National Confidential Inquiry \\ninto Suicide,\" British medical bulletin, vol. 100, pp. 101 -121, 2011.  \\n[2] M. D . Choudhury, E. Kiciman, M. Dredze, G. Coppersmith, and M. \\nKumar, \"Discovering shifts to suicidal ideation from mental health \\ncontent in social media,\" in Proceedings of the 2016 CHI Conference \\non Human Factors in Computing Systems , 2016, pp. 2098 -2110 . \\n[3] S. Ji, C. P. Yu, S. F. Fung, S. Pan, and G. Long, \"Supervised learning \\nfor suicidal ideation detection in online user content,\" Complex, 2018.  \\n[4] LangChain, https://www.langchain.com/  (accessed Nov. 29, 202 3). \\n[5] LangChain ChatModels, https://blog.langchain.dev/chat -models/ \\n(accessed Nov. 29, 2023).  \\n[6] LangChain with OpenAI Chat Model , \\nhttps://python.langchain.com/docs/integrations/chat/openai / (accessed \\nNov. 29, 2023).  [7] LangChain’s Prompt, https://python.langchain.com/docs/modules  \\n/model_io/prompts/ (accessed Nov. 29, 2023).  \\n[8] LangChain’s Chain s, https://python.langchain.com/docs/modules  \\n/chain s (accessed Nov. 29, 2023).  \\n[9] OpenAI, https://platform.openai.com/docs/quickstart?context=python \\n(accessed Nov. 29, 2023).  \\n[10] LangChain’s Message Prompt Template,  \\nhttps://python.langchain.com/docs/modules/model_io/prompts/m essa\\nge_prompt s (accessed Nov. 29, 2023).  \\n[11] LangChain’s Large Language Model Chain,  \\nhttps://python.langchain.com/docs/modules/chains/foundational/llm_c\\nhain (accessed Nov. 29, 2023).  \\n[12] Streamlit, https://streamlit.io/  (accessed Nov. 29, 2023).')]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "loader = WebBaseLoader(\"https://www.geeksforgeeks.org/search/?gq=binary+tree\")\n",
        "web_data = loader.load()\n",
        "web_data[0].page_content[:1000]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "59pIL2anuFca",
        "outputId": "89eda3c5-a14f-4dbc-e5f5-31fb9e60f1e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_community.utils.user_agent:USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'You searched for binary tree - GeeksforGeeksTutorialsCoursesGo PremiumData StructureJavaPythonHTMLInterview PreparationBinary Tree Data Structure - GeeksforGeeksLast Updated : A binary tree data structure is a hierarchical data structure in which each node has at most two children, referred to as the left child and the right child....Read MoreBoundary Traversal of binary tree - GeeksforGeeksLast Updated : The idea is to traverse the boundary of the binary tree in three parts. By combining these parts, we achieve the desired boundary traversal....Read MoreTypes of Binary Tree - GeeksforGeeksLast Updated : A binary tree is a full binary tree if every node has 0 or 2 children. The following are examples of a full binary tree....Read MoreDifference between General tree and Binary tree - GeeksforGeeksLast Updated : A binary tree is the specialized version of the General tree. A binary tree is a tree in which each node can have at most two nodes....Read MoreTop View of Binary Tree | Practice'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#since the document received could be a very large file that may overrun the outupt token for a llm\n",
        "#hence we process it in chunks\n",
        "\n",
        "#to do so we use Splitters"
      ],
      "metadata": {
        "id": "0ubGXimHudDN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "#by default text_splitter takes \"\\n\\n\" as separator i.e, at every paragraph\n",
        "text_splitter = CharacterTextSplitter(chunk_size= 200, chunk_overlap= 20, separator=\"\\n\")\n",
        "\n",
        "chunks=text_splitter.split_documents(pages)\n",
        "print(len(chunks))\n",
        "\n",
        "print(chunks[5].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNvoIxNDvMSv",
        "outputId": "0739504a-2b58-4f41-bff1-8dabfa64cf79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "148\n",
            "contextualized language models to introduce MindGuide, an \n",
            "innovative chatbot serving as a mental health assistant for \n",
            "individuals seeking guidance and support in these critical areas.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Embeddings"
      ],
      "metadata": {
        "id": "AUXId8Bq3l92"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_google_genai"
      ],
      "metadata": {
        "id": "azNXkkxX6IuU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3d9a1c3b-a269-413d-d2c2-2695f0f230db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_google_genai\n",
            "  Downloading langchain_google_genai-2.1.10-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from langchain_google_genai)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting google-ai-generativelanguage<0.7.0,>=0.6.18 (from langchain_google_genai)\n",
            "  Downloading google_ai_generativelanguage-0.6.18-py3-none-any.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.75 in /root/.local/lib/python3.12/site-packages (from langchain_google_genai) (0.3.75)\n",
            "Requirement already satisfied: pydantic<3,>=2 in /root/.local/lib/python3.12/site-packages (from langchain_google_genai) (2.11.7)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (2.25.1)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (5.29.5)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /root/.local/lib/python3.12/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (2.32.5)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (1.74.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (1.71.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (4.9.1)\n",
            "Requirement already satisfied: langsmith>=0.3.45 in /root/.local/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.75->langchain_google_genai) (0.4.20)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /root/.local/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.75->langchain_google_genai) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /root/.local/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.75->langchain_google_genai) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /root/.local/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.75->langchain_google_genai) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /root/.local/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.75->langchain_google_genai) (4.15.0)\n",
            "Requirement already satisfied: packaging>=23.2 in /root/.local/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.75->langchain_google_genai) (25.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /root/.local/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.75->langchain_google_genai) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /root/.local/lib/python3.12/site-packages (from pydantic<3,>=2->langchain_google_genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /root/.local/lib/python3.12/site-packages (from pydantic<3,>=2->langchain_google_genai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /root/.local/lib/python3.12/site-packages (from pydantic<3,>=2->langchain_google_genai) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /root/.local/lib/python3.12/site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /root/.local/lib/python3.12/site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/.local/lib/python3.12/site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /root/.local/lib/python3.12/site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (2025.8.3)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.12/dist-packages (from rsa<5,>=3.1.4->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (0.6.1)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /root/.local/lib/python3.12/site-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.75->langchain_google_genai) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /root/.local/lib/python3.12/site-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.75->langchain_google_genai) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /root/.local/lib/python3.12/site-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.75->langchain_google_genai) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /root/.local/lib/python3.12/site-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.75->langchain_google_genai) (0.24.0)\n",
            "Requirement already satisfied: anyio in /root/.local/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.75->langchain_google_genai) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /root/.local/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.75->langchain_google_genai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /root/.local/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.75->langchain_google_genai) (0.16.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /root/.local/lib/python3.12/site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.75->langchain_google_genai) (1.3.1)\n",
            "Downloading langchain_google_genai-2.1.10-py3-none-any.whl (49 kB)\n",
            "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading google_ai_generativelanguage-0.6.18-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: filetype, google-ai-generativelanguage, langchain_google_genai\n",
            "\u001b[2K  Attempting uninstall: google-ai-generativelanguage\n",
            "\u001b[2K    Found existing installation: google-ai-generativelanguage 0.6.15\n",
            "\u001b[2K    Uninstalling google-ai-generativelanguage-0.6.15:\n",
            "\u001b[2K      Successfully uninstalled google-ai-generativelanguage-0.6.15\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [langchain_google_genai]\n",
            "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.18 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed filetype-1.2.0 google-ai-generativelanguage-0.6.18 langchain_google_genai-2.1.10\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "0fe143c2170647679667483b73bbdf28"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "\n",
        "gemini_embeddings = GoogleGenerativeAIEmbeddings(\n",
        "    model=\"models/embedding-001\",\n",
        "    google_api_key=userdata.get('google-api-key')\n",
        ")\n"
      ],
      "metadata": {
        "id": "6fFfwSng4hX1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "4fb725dd-3eaf-4758-9ac6-95c67f9e600a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'langchain_google_genai'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2640924357.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_google_genai\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGoogleGenerativeAIEmbeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m gemini_embeddings = GoogleGenerativeAIEmbeddings(\n\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"models/embedding-001\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mgoogle_api_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muserdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'google-api-key'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain_google_genai'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texts= [text.page_content for text in chunks]\n",
        "\n",
        "embed_result = gemini_embeddings.embed_documents(texts)\n",
        "embed_result[0][:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDreTvNI6Sf8",
        "outputId": "7bbb53ae-2f67-45fe-df10-e29a06e00e21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.04761611670255661,\n",
              " 0.006645544432103634,\n",
              " -0.06415325403213501,\n",
              " -0.02032722905278206,\n",
              " 0.094366654753685]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import Chroma\n",
        "docsearch = Chroma.from_documents(chunks, gemini_embeddings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShF_nPu0QRdA",
        "outputId": "54a1ff25-660b-4d11-e1c8-25e8e0ec169f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Langchain\"\n",
        "docs = docsearch.similarity_search(query)\n",
        "print(docs[0].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6BC9NoZX49oI",
        "outputId": "343b2fa8-9fc2-4603-91b5-a450677fa664"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionQueryEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "blocks and pre -built chains for building large language model \n",
            "applications shows the easy way developers can do it .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retreiver  = docsearch.as_retriever()\n",
        "docs= retreiver.invoke(\"langgraph\")\n",
        "docs[0].page_content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "nP87dQy54-J1",
        "outputId": "66749b14-4da3-4a59-dd6b-d0f09b0283fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'blocks and pre -built chains for building large language model \\napplications shows the easy way developers can do it .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "qa = RetrievalQA.from_chain_type(\n",
        "    llm = llm,\n",
        "    chain_type = \"stuff\", #stuff means all documents are concatenated and passed to llm\n",
        "    retriever=docsearch.as_retriever(),\n",
        "    return_source_documents =False\n",
        ")\n",
        "\n",
        "query = \"what could be a title to the paper?\"\n",
        "qa.invoke(query)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0aGaZnbj8NPf",
        "outputId": "4bee8f09-cacc-4815-c7e8-7cc6c4bca1e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query': 'what could be a title to the paper?',\n",
              " 'result': 'Based on the abstract provided, a potential title for the paper could be:\\n\\n\"Application of Pretrained Contextualized Large Language Models for Mental Health Text Analysis\"\\n\\nThe abstract mentions that the paper explores the application of recent advancements in pretrained contextualized large language models to analyze text related to mental health challenges and disorders. So a title highlighting the use of these language models for mental health text analysis would fit well with the abstract\\'s contents.'}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o5sAPBSn9Y7Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}