{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPN5Ey72YqeK+66QBoHtyOC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/codeREXus/langchain-learnings/blob/main/Langchain2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xMqto8RXl-PH"
      },
      "outputs": [],
      "source": [
        "!pip install --force-reinstall --no-cache-dir tenacity==8.2.3 --user\n",
        "!pip install \"langchain-experimental==0.0.62\" --user\n",
        "!pip install \"langchain-community==0.2.10\" --user\n",
        "!pip install \"langchainhub==0.1.18\" --user\n",
        "!pip install \"langchain==0.2.11\" --user\n",
        "!pip install \"pypdf==4.2.0\" --user\n",
        "!pip install \"chromadb==0.4.24\" --user\n",
        "!pip install  langchain_anthropic"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --force-reinstall \"langchain-community\" --user"
      ],
      "metadata": {
        "id": "d6hCY3YfpLKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall numpy -y\n",
        "!pip install numpy==1.26.4 --user"
      ],
      "metadata": {
        "id": "DSwbrDFPLuU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "ya8QVEwDU9Qh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# You can also use this section to suppress warnings generated by your code:\n",
        "def warn(*args, **kwargs):\n",
        "    pass\n",
        "import warnings\n",
        "warnings.warn = warn\n",
        "warnings.filterwarnings('ignore')\n",
        "import os\n",
        "os.environ['ANONYMIZED_TELEMETRY'] = 'False'\n",
        "\n",
        "from langchain_anthropic import ChatAnthropic\n",
        "from langchain_core.output_parsers import CommaSeparatedListOutputParser\n",
        "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
        "from langchain_core.prompts import PromptTemplate\n"
      ],
      "metadata": {
        "id": "naQOWCHZnYDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatAnthropic(\n",
        "    model=\"claude-3-opus-20240229\",  # or claude-3-sonnet-20240229, claude-3-haiku-20240307\n",
        "    temperature=0.5,\n",
        "    max_tokens=128,\n",
        "    api_key=userdata.get('anthropic-api-key')\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "xC8USIqHoREa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to generate a simple message from the llm\n",
        "msg = llm.invoke(\"Hey! hows the day?\")\n",
        "print(msg.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_zpKRrfnNLi",
        "outputId": "db076f04-5a8f-4862-c657-ca81d04881c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "As an AI language model, I don't have personal experiences or emotions, so I don't have a day in the same sense that humans do. However, I'm here and ready to assist you with any questions or tasks you may have. How can I help you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Simulate a Chat Conversation"
      ],
      "metadata": {
        "id": "IKIz4jdto5zy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# use chatModels\n",
        "msg = llm.invoke(\n",
        "    [\n",
        "        SystemMessage(content=' you are a funny guy who jokes a lot with satire in your tone.'),\n",
        "        HumanMessage(content='i have been feeling worse over my breakup')\n",
        "        #simmilarly you cna include AIMessage in it as well\n",
        "\n",
        "        # to beautify it you can use MessagePlaceHolders as well\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(msg.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pC8P10MGnuXW",
        "outputId": "f9734024-3db3-4246-b337-066a37942e08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I'm sorry to hear that you're struggling with your breakup. It's completely normal to feel a range of emotions, including sadness, anger, and loneliness, after a relationship ends. Here are some suggestions that may help you cope with this difficult time:\n",
            "\n",
            "1. Allow yourself to grieve: It's important to acknowledge and process your emotions. Don't try to suppress or ignore them.\n",
            "\n",
            "2. Reach out for support: Talk to friends, family, or a therapist about how you're feeling. Sharing your thoughts and emotions can help you feel less alone and more supported.\n",
            "\n",
            "3. Practice\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## creating Prompt Templates"
      ],
      "metadata": {
        "id": "SSCpBxL-rSyv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt=PromptTemplate.from_template(\"tell me a cool fact about {topic}\")\n",
        "input_=prompt.format(topic=\"dogs\") ## input_={\"topic\":\"dogs\"}\n",
        "print(llm.invoke(input_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NxgQnXHaqk1d",
        "outputId": "cde41b6a-e3de-43b1-c233-2ded38fa4f27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content=\"Sure, here's a cool fact about dogs:\\n\\nDogs have a unique sense of smell that is up to 100,000 times more sensitive than humans. This is because they have around 300 million olfactory receptors in their noses, compared to only about 6 million in humans. This incredible sense of smell allows dogs to detect various scents, including drugs, explosives, and even certain diseases like cancer. In fact, some dogs are specifically trained to use their powerful noses to assist in search and rescue missions, crime investigations, and medical detection. Their keen sense of smell is one of the\" additional_kwargs={} response_metadata={'id': 'msg_01MYN8jqqEKzMpnnjNgXPQ4v', 'model': 'claude-3-opus-20240229', 'stop_reason': 'max_tokens', 'stop_sequence': None, 'usage': {'cache_creation': {'ephemeral_1h_input_tokens': 0, 'ephemeral_5m_input_tokens': 0}, 'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 14, 'output_tokens': 128, 'server_tool_use': None, 'service_tier': 'standard'}, 'model_name': 'claude-3-opus-20240229'} id='run--1e4edb8b-c217-48ca-b649-dfc8cefc8ac9-0' usage_metadata={'input_tokens': 14, 'output_tokens': 128, 'total_tokens': 142, 'input_token_details': {'cache_read': 0, 'cache_creation': 0, 'ephemeral_5m_input_tokens': 0, 'ephemeral_1h_input_tokens': 0}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Output Parser"
      ],
      "metadata": {
        "id": "r6671n_ztbio"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "from pydantic import BaseModel, Field"
      ],
      "metadata": {
        "id": "gCOJDtH3tbKz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Joke(BaseModel):\n",
        "    setup: str = Field(description=\"question to set up a joke\")\n",
        "    punchline: str = Field(description=\"answer to resolve the joke\")"
      ],
      "metadata": {
        "id": "H-Fsqg0Rq2YI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "joke= \"why cant dogs have 3 legs\"\n",
        "output_parser = JsonOutputParser(pydantic_object=Joke)\n",
        "format_instructions = output_parser.get_format_instructions()\n",
        "prompt = PromptTemplate(\n",
        "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
        "    input_variables=[\"query\"],\n",
        "    partial_variables={\"format_instructions\": format_instructions},\n",
        ")\n",
        "chain = prompt | llm | output_parser\n",
        "chain.invoke({\"query\": joke})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHYiHs3xwNdL",
        "outputId": "590fb35a-076f-4993-b303-153deced2275"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'setup': \"Why can't dogs have 3 legs?\",\n",
              " 'punchline': 'Because a dog with 3 legs would be called a tripod, not a dog!'}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_parser = CommaSeparatedListOutputParser()\n",
        "format_instructions= output_parser.get_format_instructions()\n",
        "prompt = PromptTemplate(\n",
        "    template=\"List five {topic}.\\n{format_instructions}\",\n",
        "    input_variables=[\"topic\"],\n",
        "    partial_variables={\"format_instructions\":format_instructions}\n",
        ")\n",
        "\n",
        "chain = prompt | llm | output_parser\n",
        "chain.invoke({\"topic\":\"otuerspace flavors\"})"
      ],
      "metadata": {
        "id": "0Z5TjeGMxo_Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22fa349c-d363-49a5-ccf2-27f998bb5c57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['moon cheese',\n",
              " 'asteroid ice cream',\n",
              " 'nebula nectar',\n",
              " 'cosmic cotton candy',\n",
              " 'starlight sorbet']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Working with Document"
      ],
      "metadata": {
        "id": "5ePfwPHI2q2Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.documents import Document\n",
        "Document(\n",
        "    metadata= {\n",
        "        'my_document_id':123, #unique id for the doc\n",
        "        'my_document_source':\"The LangChain Papers\" # this gives the title of the doc\n",
        "\n",
        "    },\n",
        "    page_content=\"Hey! my name is Anant Srivastava. These documents are a sample while learning langchain and LLMs..\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-x1ztvY046A",
        "outputId": "3c357c23-0a0e-41e7-9bdb-ea992bf83089"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(metadata={'my_document_id': 123, 'my_document_source': 'The LangChain Papers'}, page_content='Hey! my name is Anant Srivastava. These documents are a sample while learning langchain and LLMs..')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# an external document is loaded by loaders. these loaders are of different types\n",
        "# we are usign WebBaseLoader and PyPDFLooder\n",
        "\n",
        "\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "loader = PyPDFLoader(\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/96-FDF8f7coh0ooim7NyEQ/langchain-paper.pdf\")\n",
        "pages = loader.load()"
      ],
      "metadata": {
        "id": "rwvyhZ223qQD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pages"
      ],
      "metadata": {
        "id": "3XoSiFTFouNp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "loader = WebBaseLoader(\"https://www.geeksforgeeks.org/search/?gq=binary+tree\")\n",
        "web_data = loader.load()\n",
        "web_data[0].page_content[:1000]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "59pIL2anuFca",
        "outputId": "89eda3c5-a14f-4dbc-e5f5-31fb9e60f1e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_community.utils.user_agent:USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'You searched for binary tree - GeeksforGeeksTutorialsCoursesGo PremiumData StructureJavaPythonHTMLInterview PreparationBinary Tree Data Structure - GeeksforGeeksLast Updated : A binary tree data structure is a hierarchical data structure in which each node has at most two children, referred to as the left child and the right child....Read MoreBoundary Traversal of binary tree - GeeksforGeeksLast Updated : The idea is to traverse the boundary of the binary tree in three parts. By combining these parts, we achieve the desired boundary traversal....Read MoreTypes of Binary Tree - GeeksforGeeksLast Updated : A binary tree is a full binary tree if every node has 0 or 2 children. The following are examples of a full binary tree....Read MoreDifference between General tree and Binary tree - GeeksforGeeksLast Updated : A binary tree is the specialized version of the General tree. A binary tree is a tree in which each node can have at most two nodes....Read MoreTop View of Binary Tree | Practice'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#since the document received could be a very large file that may overrun the outupt token for a llm\n",
        "#hence we process it in chunks\n",
        "\n",
        "#to do so we use Splitters"
      ],
      "metadata": {
        "id": "0ubGXimHudDN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "#by default text_splitter takes \"\\n\\n\" as separator i.e, at every paragraph\n",
        "text_splitter = CharacterTextSplitter(chunk_size= 200, chunk_overlap= 20, separator=\"\\n\")\n",
        "\n",
        "chunks=text_splitter.split_documents(pages)\n",
        "print(len(chunks))\n",
        "\n",
        "print(chunks[5].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNvoIxNDvMSv",
        "outputId": "0739504a-2b58-4f41-bff1-8dabfa64cf79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "148\n",
            "contextualized language models to introduce MindGuide, an \n",
            "innovative chatbot serving as a mental health assistant for \n",
            "individuals seeking guidance and support in these critical areas.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Embeddings"
      ],
      "metadata": {
        "id": "AUXId8Bq3l92"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_google_genai"
      ],
      "metadata": {
        "id": "azNXkkxX6IuU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "\n",
        "gemini_embeddings = GoogleGenerativeAIEmbeddings(\n",
        "    model=\"models/embedding-001\",\n",
        "    google_api_key=userdata.get('google-api-key')\n",
        ")\n"
      ],
      "metadata": {
        "id": "6fFfwSng4hX1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "4fb725dd-3eaf-4758-9ac6-95c67f9e600a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'langchain_google_genai'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2640924357.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_google_genai\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGoogleGenerativeAIEmbeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m gemini_embeddings = GoogleGenerativeAIEmbeddings(\n\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"models/embedding-001\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mgoogle_api_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muserdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'google-api-key'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain_google_genai'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texts= [text.page_content for text in chunks]\n",
        "\n",
        "embed_result = gemini_embeddings.embed_documents(texts)\n",
        "embed_result[0][:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDreTvNI6Sf8",
        "outputId": "7bbb53ae-2f67-45fe-df10-e29a06e00e21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.04761611670255661,\n",
              " 0.006645544432103634,\n",
              " -0.06415325403213501,\n",
              " -0.02032722905278206,\n",
              " 0.094366654753685]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import Chroma\n",
        "docsearch = Chroma.from_documents(chunks, gemini_embeddings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShF_nPu0QRdA",
        "outputId": "54a1ff25-660b-4d11-e1c8-25e8e0ec169f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Langchain\"\n",
        "docs = docsearch.similarity_search(query)\n",
        "print(docs[0].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6BC9NoZX49oI",
        "outputId": "343b2fa8-9fc2-4603-91b5-a450677fa664"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionQueryEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "blocks and pre -built chains for building large language model \n",
            "applications shows the easy way developers can do it .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retreiver  = docsearch.as_retriever()\n",
        "docs= retreiver.invoke(\"langgraph\")\n",
        "docs[0].page_content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "nP87dQy54-J1",
        "outputId": "66749b14-4da3-4a59-dd6b-d0f09b0283fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'blocks and pre -built chains for building large language model \\napplications shows the easy way developers can do it .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "qa = RetrievalQA.from_chain_type(\n",
        "    llm = llm,\n",
        "    chain_type = \"stuff\", #stuff means all documents are concatenated and passed to llm\n",
        "    retriever=docsearch.as_retriever(),\n",
        "    return_source_documents =False\n",
        ")\n",
        "\n",
        "query = \"what could be a title to the paper?\"\n",
        "qa.invoke(query)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0aGaZnbj8NPf",
        "outputId": "4bee8f09-cacc-4815-c7e8-7cc6c4bca1e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query': 'what could be a title to the paper?',\n",
              " 'result': 'Based on the abstract provided, a potential title for the paper could be:\\n\\n\"Application of Pretrained Contextualized Large Language Models for Mental Health Text Analysis\"\\n\\nThe abstract mentions that the paper explores the application of recent advancements in pretrained contextualized large language models to analyze text related to mental health challenges and disorders. So a title highlighting the use of these language models for mental health text analysis would fit well with the abstract\\'s contents.'}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o5sAPBSn9Y7Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}