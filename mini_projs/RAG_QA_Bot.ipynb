{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMPM/hjSjwDr41TdZJy+CNy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/codeREXus/langchain-learnings/blob/main/mini_projs/RAG_QA_Bot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " # **Rag QA Bot**\n"
      ],
      "metadata": {
        "id": "138gL9U4pZHu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Z_c7LEUApNQY"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install \"langchain_google_genai\"\n",
        "!pip install \"langchain\"\n",
        "!pip install \"transformers==4.41.2\"\n",
        "!pip install  \"huggingface-hub==0.23.4\"\n",
        "!pip install  \"sentence-transformers==2.5.1\"\n",
        "!pip install  \"chromadb\"\n",
        "!pip install  \"langchain-community\"\n",
        "!pip install  \"wget==3.2\"\n",
        "!pip install --upgrade torch --index-url https://download.pytorch.org/whl/cpu"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def warn(*args, **kwargs):\n",
        "    pass\n",
        "import warnings\n",
        "warnings.warn = warn\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "from langchain_google_genai import GoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
        "import wget"
      ],
      "metadata": {
        "id": "QxNuVJkjqT2J"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n"
      ],
      "metadata": {
        "id": "il1tS__8xURV"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Rag Archtecture**\n",
        "\n",
        "\n",
        "## 1.   Indexing\n",
        "\n",
        "\n",
        "*   Load data\n",
        "*   Pre-process\n",
        "*   Split into chunks\n",
        "*   Embed as vectors\n",
        "* Store in vector db\n",
        "\n",
        "\n",
        "## 2.   Retreival and generation\n",
        "* Retrival - search for similar vectors, to match prompt\n",
        "* generaion - model results with output from the prompt\n",
        "\n"
      ],
      "metadata": {
        "id": "fZMgkyr9tBBW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load data"
      ],
      "metadata": {
        "id": "IddNOEopucIT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filename = 'companyPolicies.txt'\n",
        "url = input('Put the link to your document here: ')\n",
        "\n",
        "# Use wget to download the file\n",
        "wget.download(url, out=filename)\n",
        "print('file downloaded')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fj83rKBBq2_f",
        "outputId": "0de58b74-a03f-4a83-f179-5f71e506eac1"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Put the link to your document here: https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/6JDbUb_L3egv_eOkouY71A.txt\n",
            "file downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(filename, 'r') as file:\n",
        "    # Read the contents of the file\n",
        "    contents = file.read()\n",
        "    print(len(contents.split(\"\\n\\n\")))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfWWfrJauM2G",
        "outputId": "c2af8fc3-c4fe-49ca-cb6d-e1c7d35b9af1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "94\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split into chunks"
      ],
      "metadata": {
        "id": "tTFjxNKPujGT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loader = TextLoader(filename)\n",
        "docs = loader.load()\n",
        "text_splitter  = CharacterTextSplitter(chunk_size= 1000,separator=\"\\n\",chunk_overlap = 0)\n",
        "texts = text_splitter.split_documents(docs)\n",
        "print(len(texts))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0w-H1QUuQgq",
        "outputId": "d68fe1c9-884a-4785-b7e2-3ed081ce0363"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Embedding\n",
        "we will have a qualitative analysis of a huggingface embeder and gemini embeder"
      ],
      "metadata": {
        "id": "OzUuqzHqwjJr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hg_embeding= HuggingFaceEmbeddings()\n",
        "hg_docsearch = Chroma.from_documents(texts, hg_embeding)\n",
        "\n",
        "g_embedding = GoogleGenerativeAIEmbeddings(\n",
        "    model=\"models/embedding-001\",\n",
        "    google_api_key=userdata.get('google-api-key')\n",
        ")\n",
        "g_docsearch = Chroma.from_documents(texts, g_embedding)\n",
        "print(\"ingested\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZENzJ49Pvq3P",
        "outputId": "124a37c5-6f04-4821-c874-29b4913e194a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ingested\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Intialise a llm\n"
      ],
      "metadata": {
        "id": "2swM4aOZzWBJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pprint"
      ],
      "metadata": {
        "id": "Xj_F7Iwc4CIu"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm=GoogleGenerativeAI(\n",
        "    model='gemini-1.5-flash-latest',\n",
        "    google_api_key=userdata.get('google-api-key')\n",
        ")"
      ],
      "metadata": {
        "id": "NNzBKtuXzVvV"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# run the chain/qa bot"
      ],
      "metadata": {
        "id": "LVcIXRFN5DoX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "qa = RetrievalQA.from_chain_type(llm=llm,\n",
        "                                 chain_type=\"stuff\",\n",
        "                                 retriever=hg_docsearch.as_retriever(),\n",
        "                                 return_source_documents=False)\n",
        "query = \"can you summarise the document for me?\"\n",
        "pprint.pprint(qa.invoke(query))\n",
        "print(len(query))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okGON_lCxcLt",
        "outputId": "4c6cc9bd-5c9a-4f03-c122-29d5edf4276c"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'query': 'can you summarise the document for me?',\n",
            " 'result': 'The provided text consists of two identical sections outlining a '\n",
            "           \"company's Code of Conduct and a Recruitment Policy.  The Code of \"\n",
            "           'Conduct emphasizes integrity, respect, accountability, safety, and '\n",
            "           'environmental responsibility.  It details expectations for ethical '\n",
            "           'behavior, diversity and inclusion, responsible reporting, and '\n",
            "           'sustainable practices.  The Recruitment Policy is identical to the '\n",
            "           \"Code of Conduct, indicating that the company's recruitment \"\n",
            "           'practices are guided by the same ethical principles.'}\n",
            "38\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Markdown\n",
        "\n",
        "# 1. Invoke the chain\n",
        "response = qa.invoke(query)\n",
        "\n",
        "# 2. Safely get the query and result\n",
        "query_text = response.get('query', 'No query found.')\n",
        "result_text = response.get('result', 'No result found.')\n",
        "\n",
        "# 3. Create a formatted Markdown string\n",
        "markdown_output = f\"\"\"\n",
        "### 📝 Query\n",
        "> {query_text}\n",
        "\n",
        "---\n",
        "\n",
        "### 💡 Answer\n",
        "> {result_text}\n",
        "\"\"\"\n",
        "\n",
        "# 4. Display the rendered Markdown\n",
        "display(Markdown(markdown_output))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "t3FusWqc4rqw",
        "outputId": "b4936db2-a641-4d28-b2ab-70815a8b4500"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\n### 📝 Query\n> can you summarise the document for me?\n\n---\n\n### 💡 Answer\n> The provided text consists of two identical sections outlining a company's Code of Conduct and a Recruitment Policy (which is also identical to the Code of Conduct).  The Code of Conduct emphasizes integrity, respect, accountability, safety, and environmental responsibility.  It details expectations for ethical behavior, inclusivity, adherence to laws, and proactive safety measures.  The document stresses that the Code of Conduct is a foundational element of the company culture.\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qa = RetrievalQA.from_chain_type(llm=llm,\n",
        "                                 chain_type=\"stuff\",\n",
        "                                 retriever=g_docsearch.as_retriever(),\n",
        "                                 return_source_documents=False)\n",
        "query = \"Can  mobiles be used for gaming in the company?\"\n",
        "pprint.pprint(qa.invoke(query))\n",
        "print(len(query))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHu4MPBKzKM5",
        "outputId": "e2f251be-3f2f-4fe6-b7ee-2d37b5bc6121"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'query': 'Can  mobiles be used for gaming in the company?',\n",
            " 'result': 'The provided text does not explicitly address the use of mobile '\n",
            "           \"devices for gaming.  Therefore, I don't know.\"}\n",
            "47\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Markdown\n",
        "\n",
        "response = qa.invoke(query)\n",
        "\n",
        "query_text = response.get('query', 'No query found.')\n",
        "result_text = response.get('result', 'No result found.')\n",
        "\n",
        "markdown_output = f\"\"\"\n",
        "### 📝 Query\n",
        "> {query_text}\n",
        "\n",
        "---\n",
        "\n",
        "### 💡 Answer\n",
        "> {result_text}\n",
        "\"\"\"\n",
        "\n",
        "display(Markdown(markdown_output))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "id": "W55rpmNz0h4L",
        "outputId": "497b9d9e-7a79-4900-8db7-7f15f6c484a6"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\n### 📝 Query\n> Can  mobiles be used for gaming in the company?\n\n---\n\n### 💡 Answer\n> The provided text does not explicitly address the use of mobile devices for gaming.  Therefore, I don't know.\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# To prevent from hallucination and wrongful generation of texts we are setting up a prompt\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "*   Without your prompt: The LLM behaved like a helpful general assistant. It prioritized giving a useful answer, even if it had to use its own knowledge.\n",
        "*   With your prompt: You forced the LLM to behave like a strict document analyst. Its only job is to report what's in the document and nothing else.\n"
      ],
      "metadata": {
        "id": "0HO9ciup554I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = \"\"\"Use the information from the document to answer the question at the end. If you don't know the answer, just say that you don't know, definately do not try to make up an answer.\n",
        "\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "\n",
        "PROMPT = PromptTemplate(\n",
        "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
        ")\n",
        "\n",
        "chain_type_kwargs = {\"prompt\": PROMPT}\n",
        "\n",
        "#context and question are keywords in the RetrievalQA, so LangChain can automatically recognize them as document content and query."
      ],
      "metadata": {
        "id": "X5ArnEB055sC"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa = RetrievalQA.from_chain_type(llm=llm,\n",
        "                                 chain_type=\"stuff\",\n",
        "                                 retriever=hg_docsearch.as_retriever(),\n",
        "                                 chain_type_kwargs=chain_type_kwargs,\n",
        "                                 return_source_documents=False)\n",
        "\n",
        "query = \"Can I steal company vehicles?\"\n",
        "qa.invoke(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbPyOSTp5L8D",
        "outputId": "1d45d7bb-f76d-492a-8b81-33e470dd3661"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query': 'Can I steal company vehicles?',\n",
              " 'result': \"The provided text does not address the issue of stealing company vehicles.  Therefore, I don't know.\"}"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lets set up memory as well. This would help in connecting thoughts and prompts as well (demo)"
      ],
      "metadata": {
        "id": "7u2tWvs09mV7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "memory = ConversationBufferMemory(memory_key = \"chat_history\", return_message = True)"
      ],
      "metadata": {
        "id": "s2RIrn4j6v8k"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa = ConversationalRetrievalChain.from_llm(llm=llm,\n",
        "                                           chain_type=\"stuff\",\n",
        "                                           retriever=hg_docsearch.as_retriever(),\n",
        "                                           memory = memory,\n",
        "                                           get_chat_history=lambda h : h,\n",
        "                                           return_source_documents=False)"
      ],
      "metadata": {
        "id": "DokYzsEp9w8K"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = []\n",
        "query = \"What is smoking policy?\"\n",
        "result = qa.invoke({\"question\":query}, {\"chat_history\": history})\n",
        "print(result[\"answer\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdAX06Mo910P",
        "outputId": "519709ca-3cb5-447f-fbf8-e6ebaff14cf4"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Smoking is only permitted in designated outdoor areas marked by signage.  Smoking is prohibited inside all company buildings, offices, meeting rooms, enclosed spaces, and company vehicles.  Electronic cigarettes and vaping devices are also prohibited.  Proper disposal of smoking materials is required. Failure to comply may result in disciplinary action, including fines or termination of employment.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history.append((query, result[\"answer\"]))"
      ],
      "metadata": {
        "id": "BI30Orsz-T_-"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"List points in it?\"\n",
        "result = qa({\"question\": query}, {\"chat_history\": history})\n",
        "print(result[\"answer\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8KnGlEK-k3_",
        "outputId": "600ac481-a6a6-4c24-8eb8-8234e0ee9faf"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The key points of the smoking policy are:\n",
            "\n",
            "* **Designated Smoking Areas:** Smoking is only allowed in designated areas marked by signage.\n",
            "* **Smoking Restrictions:** Smoking is prohibited inside buildings, offices, meeting rooms, and enclosed spaces.  This includes e-cigarettes and vaping devices.  It is also prohibited in company vehicles.\n",
            "* **Compliance with Laws:** All must follow federal, state, and local smoking laws.\n",
            "* **Waste Disposal:**  Proper disposal of smoking materials in designated receptacles is required. Littering is prohibited.\n",
            "* **Enforcement:** Non-compliance can lead to disciplinary action, including fines or termination for employees.\n",
            "* **Policy Review:** The policy is regularly reviewed to ensure it aligns with current laws and best practices.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# lets finish it up"
      ],
      "metadata": {
        "id": "aKJbpH_1_HPV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def qa():\n",
        "    memory = ConversationBufferMemory(memory_key = \"chat_history\", return_message = True,output_key='answer')\n",
        "    qa = ConversationalRetrievalChain.from_llm(llm=llm,\n",
        "                                               chain_type=\"stuff\",\n",
        "                                               retriever=hg_docsearch.as_retriever(),\n",
        "                                               memory = memory,\n",
        "                                               get_chat_history=lambda h : h,\n",
        "                                               chain_type_kwargs=chain_type_kwargs,\n",
        "                                               return_source_documents=True)\n",
        "    history = []\n",
        "    while True:\n",
        "        query = input(\"Question: \")\n",
        "\n",
        "        if query.lower() in [\"quit\",\"exit\",\"bye\"]:\n",
        "            print(\"Answer: Goodbye!\")\n",
        "            break\n",
        "\n",
        "        result = qa({\"question\": query}, {\"chat_history\": history})\n",
        "\n",
        "        history.append((query, result[\"answer\"]))\n",
        "\n",
        "        print(\"Answer: \", result[\"answer\"])\n",
        "        print(\"source: \", result['source_documents'][0])"
      ],
      "metadata": {
        "id": "vKSieFLz_GhP"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pn6c3-ui-llI",
        "outputId": "c2771fe0-bb9d-4e04-cab8-afee899d06b7"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: can i use my personal phone\n",
            "Answer:  The policy allows limited personal use of mobile devices, provided it doesn't disrupt work obligations.  It also specifies that personal phone usage should be kept separate from company accounts, and any personal charges on company-issued phones must be reimbursed.\n",
            "source:  [Document(metadata={'source': 'companyPolicies.txt'}, page_content='The Mobile Phone Policy sets forth the standards and expectations governing the appropriate and responsible usage of mobile devices in the organization. The purpose of this policy is to ensure that employees utilize mobile phones in a manner consistent with company values and legal compliance.\\nAcceptable Use: Mobile devices are primarily intended for work-related tasks. Limited personal usage is allowed, provided it does not disrupt work obligations.\\nSecurity: Safeguard your mobile device and access credentials. Exercise caution when downloading apps or clicking links from unfamiliar sources. Promptly report security concerns or suspicious activities related to your mobile device.\\nConfidentiality: Avoid transmitting sensitive company information via unsecured messaging apps or emails. Be discreet when discussing company matters in public spaces.'), Document(metadata={'source': 'companyPolicies.txt'}, page_content='The Mobile Phone Policy sets forth the standards and expectations governing the appropriate and responsible usage of mobile devices in the organization. The purpose of this policy is to ensure that employees utilize mobile phones in a manner consistent with company values and legal compliance.\\nAcceptable Use: Mobile devices are primarily intended for work-related tasks. Limited personal usage is allowed, provided it does not disrupt work obligations.\\nSecurity: Safeguard your mobile device and access credentials. Exercise caution when downloading apps or clicking links from unfamiliar sources. Promptly report security concerns or suspicious activities related to your mobile device.\\nConfidentiality: Avoid transmitting sensitive company information via unsecured messaging apps or emails. Be discreet when discussing company matters in public spaces.'), Document(metadata={'source': 'companyPolicies.txt'}, page_content='Cost Management: Keep personal phone usage separate from company accounts and reimburse the company for any personal charges on company-issued phones.\\nCompliance: Adhere to all pertinent laws and regulations concerning mobile phone usage, including those related to data protection and privacy.\\nLost or Stolen Devices: Immediately report any lost or stolen mobile devices to the IT department or your supervisor.\\nConsequences: Non-compliance with this policy may lead to disciplinary actions, including the potential loss of mobile phone privileges.\\nThe Mobile Phone Policy is aimed at promoting the responsible and secure use of mobile devices in line with legal and ethical standards. Every employee is expected to comprehend and abide by these guidelines. Regular reviews of the policy ensure its ongoing alignment with evolving technology and security best practices.\\n5.\\tSmoking Policy'), Document(metadata={'source': 'companyPolicies.txt'}, page_content='Cost Management: Keep personal phone usage separate from company accounts and reimburse the company for any personal charges on company-issued phones.\\nCompliance: Adhere to all pertinent laws and regulations concerning mobile phone usage, including those related to data protection and privacy.\\nLost or Stolen Devices: Immediately report any lost or stolen mobile devices to the IT department or your supervisor.\\nConsequences: Non-compliance with this policy may lead to disciplinary actions, including the potential loss of mobile phone privileges.\\nThe Mobile Phone Policy is aimed at promoting the responsible and secure use of mobile devices in line with legal and ethical standards. Every employee is expected to comprehend and abide by these guidelines. Regular reviews of the policy ensure its ongoing alignment with evolving technology and security best practices.\\n5.\\tSmoking Policy')]\n",
            "Question: exit\n",
            "Answer: Goodbye!\n"
          ]
        }
      ]
    }
  ]
}