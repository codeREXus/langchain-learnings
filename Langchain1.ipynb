{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/codeREXus/langchain-learnings/blob/main/Langchain1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ASa4qSQFTbLi"
      },
      "outputs": [],
      "source": [
        "!pip install  langchain-anthropic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yMeQqzQ-TBoU"
      },
      "outputs": [],
      "source": [
        "from langchain_core.runnables import RunnableParallel\n",
        "from langchain_anthropic import ChatAnthropic\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnableLambda\n",
        "\n",
        "\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.runnables import RunnableLambda\n",
        "from langchain_core.output_parsers import StrOutputParser"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n"
      ],
      "metadata": {
        "id": "hTbLg_pjWFKq"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mgfW2x0NTyBp"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "llm = ChatAnthropic(\n",
        "    model=\"claude-3-opus-20240229\",  # or claude-3-sonnet-20240229, claude-3-haiku-20240307\n",
        "    temperature=0.5,\n",
        "    api_key=userdata.get('anthropic-api-key')\n",
        ")\n",
        "chain= {\n",
        "    \"summary\":ChatPromptTemplate.from_template(\"Summarize this text: {text}\") | llm ,\n",
        "    \"translation\":ChatPromptTemplate.from_template(\"Translate this text from English to French: {text}\") | llm,\n",
        "    \"sentiment\":ChatPromptTemplate.from_template(\"Classify the sentiment of the following text: {text}\") | llm\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-INdovg1VD_a",
        "outputId": "09c5d9d9-512f-4120-f8aa-c869371cc115"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The sentiment of the text \"I really enjoyed the conference today\" is positive. The word \"enjoyed\" expresses a positive feeling or experience, and the adverb \"really\" intensifies the positive sentiment, indicating that the speaker had a very pleasant and satisfying time at the conference.\n"
          ]
        }
      ],
      "source": [
        "result = chain['sentiment'].invoke({\"text\":\"I really  enjoyed the conference today\"})\n",
        "print(result.content)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define a function to ensure proper formatting\n",
        "def format_prompt(variables):\n",
        "    return prompt.format(**variables)"
      ],
      "metadata": {
        "id": "8fDKGoG4jowA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "description = \"\"\"\n",
        "    Retrieve the names and email addresses of all customers from the 'customers' table who have made a purchase in the last 30 days.\n",
        "    The table 'purchases' contains a column 'purchase_date'\n",
        "\"\"\"\n",
        "\n",
        "template = \"\"\"\n",
        "    Generate an SQL query based on the {description}\n",
        "\n",
        "    SQL Query:\n",
        "\n",
        "\"\"\"\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "# Create the LCEL chain\n",
        "sql_generation_chain = (\n",
        "    RunnableLambda(format_prompt)\n",
        "    | llm\n",
        ")\n",
        "\n",
        "# Run the chain\n",
        "sql_query = sql_generation_chain.invoke({\"description\": description})\n",
        "print(sql_query.content)"
      ],
      "metadata": {
        "id": "pGlynFt0ja0l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets do a task"
      ],
      "metadata": {
        "id": "TVz7ARJIli2v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain, SequentialChain\n",
        "template=\"\"\" Your job is to get a famous dish from the location that user suggests. {location}\n",
        "              your response:\"\"\"\n",
        "prompt_temp = PromptTemplate(template= template, input_variables=['location'])\n",
        "location_chain=LLMChain(llm=llm , prompt=prompt_temp , output_key= \"meal\")\n",
        "\n",
        "\n",
        "template=\"\"\"Given a meal {meal}, give a short and simple recepie on how to make that dish\"\"\"\n",
        "prompt_temp = PromptTemplate(template=template, input_variables=[\"meal\"])\n",
        "dish_chain =LLMChain(llm= llm , prompt=prompt_temp, output_key=\"recepie\")\n",
        "\n",
        "template= \"\"\"GIven a recepie{recepie}, estimate what time would a begginer take to make it\"\"\"\n",
        "prompt_temp = PromptTemplate(template = template,input_variables=[\"recepie\"])\n",
        "time_chain=LLMChain(llm= llm, prompt=prompt_temp,output_key=\"time\")"
      ],
      "metadata": {
        "id": "-AgTIxgLNVwb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = SequentialChain(chains=[location_chain, dish_chain, time_chain],\n",
        "                         input_variables=['location'],\n",
        "                         output_variables=['meal','recepie','time'],\n",
        "                        verbose=True\n",
        "                        )\n",
        "chain.invoke(input={\"location\":\"India\"})"
      ],
      "metadata": {
        "id": "Op9LYxCpQvdX"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPD5mjpJOZ9FMl357CCXeYS",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}